{"cells":[{"source":"# Practical Exam: Customer Purchase Prediction\n\nRetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n\nThe company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n\nTheir marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior.\n\nAs an AI Engineer, you will help build this prediction system. Your work will directly impact RetailTech's growth strategy and their goal of increasing revenue.\n\n\n## Data Description\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"8d0bcede-0826-475c-8678-72835c042b37","cell_type":"markdown"},{"source":"# Task 1\n\nThe marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\nCreate a cleaned version of the dataframe:\n\n- Start with the data in the file `raw_customer_data.csv`\n- Your output should be a DataFrame named `clean_data`\n- All column names and values should match the table below.\n</br>\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"c0d5a3bb-bbae-4d39-a6c6-daa46c470347","cell_type":"markdown"},{"source":"# Write your answer to Task 1 here \nimport pandas as pd\n\n# Load raw data\nraw_data = pd.read_csv(\"raw_customer_data.csv\")\n\n# --- Cleaning ---\nclean_data = raw_data.copy()\n\n# customer_id → integer (unique, no missing)\nclean_data[\"customer_id\"] = clean_data[\"customer_id\"].astype(int)\n\n# time_spent → float, fill missing with median\nclean_data[\"time_spent\"] = clean_data[\"time_spent\"].astype(float)\nclean_data[\"time_spent\"] = clean_data[\"time_spent\"].fillna(clean_data[\"time_spent\"].median())\n\n# pages_viewed → int, fill missing with mean\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].fillna(clean_data[\"pages_viewed\"].mean())\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].astype(int)\n\n# basket_value → float, fill missing with 0\nclean_data[\"basket_value\"] = clean_data[\"basket_value\"].fillna(0.0).astype(float)\n\n# device_type → string, fill missing with \"Unknown\"\nclean_data[\"device_type\"] = clean_data[\"device_type\"].fillna(\"Unknown\").astype(str)\n\n# customer_type → string, fill missing with \"New\"\nclean_data[\"customer_type\"] = clean_data[\"customer_type\"].fillna(\"New\").astype(str)\n\n# purchase → binary int (0/1)\nclean_data[\"purchase\"] = clean_data[\"purchase\"].astype(int)\n\n# Final output\nclean_data\n","metadata":{"executionCancelledAt":null,"executionTime":40,"lastExecutedAt":1755978505181,"lastExecutedByKernel":"4e5ba344-4ca8-4599-9705-ae72ac1e68a5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Write your answer to Task 1 here \nimport pandas as pd\n\n# Load raw data\nraw_data = pd.read_csv(\"raw_customer_data.csv\")\n\n# --- Cleaning ---\nclean_data = raw_data.copy()\n\n# customer_id → integer (unique, no missing)\nclean_data[\"customer_id\"] = clean_data[\"customer_id\"].astype(int)\n\n# time_spent → float, fill missing with median\nclean_data[\"time_spent\"] = clean_data[\"time_spent\"].astype(float)\nclean_data[\"time_spent\"] = clean_data[\"time_spent\"].fillna(clean_data[\"time_spent\"].median())\n\n# pages_viewed → int, fill missing with mean\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].fillna(clean_data[\"pages_viewed\"].mean())\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].astype(int)\n\n# basket_value → float, fill missing with 0\nclean_data[\"basket_value\"] = clean_data[\"basket_value\"].fillna(0.0).astype(float)\n\n# device_type → string, fill missing with \"Unknown\"\nclean_data[\"device_type\"] = clean_data[\"device_type\"].fillna(\"Unknown\").astype(str)\n\n# customer_type → string, fill missing with \"New\"\nclean_data[\"customer_type\"] = clean_data[\"customer_type\"].fillna(\"New\").astype(str)\n\n# purchase → binary int (0/1)\nclean_data[\"purchase\"] = clean_data[\"purchase\"].astype(int)\n\n# Final output\nclean_data\n","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"202a8caf-26e5-42eb-8ac1-bc38f27a76c1","nodeType":"const"}}}}},"id":"5ce18b54-29af-4beb-bc8c-79c4e21bcd52","cell_type":"code","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"time_spent","type":"number"},{"name":"pages_viewed","type":"integer"},{"name":"basket_value","type":"number"},{"name":"device_type","type":"string"},{"name":"customer_type","type":"string"},{"name":"purchase","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],"customer_id":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],"time_spent":[23.097867012,57.0921440782,44.1876425669,36.3208505676,10.2050997861,10.2036766998,35.037329193,52.1043926007,36.4657856928,42.77628209,35.037329193,58.2246812776,50.1141158072,13.52800753,11.7276730652,11.8208660814,18.9502923346,31.9606294663,26.4847560999,18.1825192717,37.0993207886,9.2301377785,18.2365342636,22.6153487543,27.9081290688,47.3253817222,12.7807531473,31.3398318664,35.9524595629,35.037329193,36.8451462622,11.0609232976,35.037329193,56.9842466979,57.9722899514,48.6954435389,18.9722123812,35.037329193,41.3697485642,26.9689971306,8.2002558558,30.2154376966,35.037329193,54.6499037226,16.2680189144,40.0888147769,19.3909534893,31.6840132495,33.2559064813,11.906412876,58.2054930381,46.7328365783,56.4304375523,53.7948136752,36.2760987499,55.3905798664,35.037329193,12.5629888827,35.037329193,20.194489515,23.9319600917,17.0095928747,49.89551304,22.0484462749,17.5751360716,33.0190689063,9.3145292735,48.3296218645,35.037329193,59.2263292594,46.5624413885,12.7242252105,35.037329193,49.1122242788,42.704583287,44.0114229144,46.5049504545,35.037329193,22.1494779841,7.836274512,51.9231021267,37.7745894828,20.5229834663,35.037329193,19.3479569812,20.1858159996,44.0467645219,38.61589081,53.345551812,28.8606805846,8.0560605104,43.0814424462,45.8863178684,34.1153546566,46.4870636173,30.1339401855,31.8412369335,26.2249200832,35.037329193,7.3655941926,35.037329193,38.5482142646,19.5470028835,31.0056707787,54.5464219616,15.7082415198,25.2125924591,45.577517174,14.499091764,35.037329193,18.0953357219,10.512055948,55.8521614882,48.6791023943,38.3708216341,52.4161748211,48.416652537,12.0076334743,53.6609809109,32.821192273,48.6389691547,53.8693866955,19.7622050233,7.4930635471,14.44817459,26.1993595289,49.2628711894,51.7831044121,35.037329193,31.1340908521,25.6272491858,14.1043608178,8.0720566727,20.9192951128,56.6316725308,20.0689729892,31.6086466829,42.4781185748,22.4541465404,58.3351428805,57.7843904016,15.8551554537,30.3376618477,18.7518202792,17.8055891683,35.037329193,36.9642957048,30.6580623705,35.037329193,17.44014139,54.587687272,15.1341515494,9.5487974534,29.8777128564,59.1533767925,15.2812610192,40.6559972969,45.9355573044,15.0206150956,43.9647645681,22.6992048304,38.306044005,38.3782529349,32.6107063604,35.037329193,50.2828472398,19.9260238333,12.0045921136,35.037329193,35.8626836481,40.9762973487,35.037329193,31.2134904397,14.3632507367,39.0651946342,11.2876193113,41.765326548,23.8173854317,56.2670693355,9.1137357046,21.122914712,7.6949377532,55.5569234784,52.7630218495,16.2185560352,39.939058716,49.2161098119,33.7568478844,32.249384123,15.2692851631,35.037329193,53.9357297192,54.1246653726,38.3529859791,21.0027576719,21.6033649021,43.8313850533,53.9295053372,53.3380990316,47.0126572056,38.8798671231,35.037329193,10.5360941316,54.0146971231,36.7793145199,35.037329193,6.9868210291,40.1466043774,35.037329193,10.4876750336,33.3752935726,41.8218166639,39.4657143107,14.2318892582,43.0185740595,14.9976961623,20.1985821914,45.042992902,39.3283410438,51.1041812192,39.7991606457,34.5302075968,35.037329193,22.6952323805,16.6469396932,15.3953889594,58.4076227304,24.1927657553,53.6307467554,38.2371789338,47.893866909,30.6555884932,35.037329193,30.0585439353,12.5193362801,43.6246748004,17.565569384,35.037329193,39.0828654585,11.449530085,56.4870564768,57.2817860432,54.976999023,22.8393633151,35.037329193,55.7707951927,26.2628647507,58.0326343236,57.8535786483,51.3275578726,18.3724846321,23.7207659875,51.2170636195,19.6983983042,11.0000720545,33.851274485,56.2331316755,42.0657580038,34.6336090353,35.037329193,37.2854263753,59.4131771562,9.264956899,31.5814494895,52.7650112437,44.7053484475,42.1239287187,42.4465609552,22.209977922,18.3219188116,48.7523081732,48.7966902861,52.1572667962,54.8811926008,31.1692015328,30.5894613865,48.099415559,39.3478719159,42.4160457582,47.9517674967,53.5103151672,20.9417142542,23.1593942058,35.037329193,35.1185283188,35.037329193,28.4702830698,33.0160334477,17.9059338756,35.8591623736,35.037329193,35.037329193,49.5334330789,22.2512478433,8.4965702465,31.8123523432,46.4296196328,13.7334406223,37.7505380733,35.037329193,35.037329193,32.3499232625,32.897472175,38.6083641884,43.8393886896,58.5752726883,31.4617205498,20.0544319035,47.9159854914,16.9791028245,26.8993138216,35.037329193,35.037329193,57.796256466,50.3228271102,42.0624781595,25.1282237204,11.2243648842,10.2297855176,15.7643309917,33.4043732177,43.1611594393,39.9516452263,17.5160999198,57.3370515591,44.5359180851,33.7068890982,37.0915240278,25.7564036832,15.6161283806,22.0023880404,45.7129205174,35.037329193,7.8482857899,35.037329193,35.037329193,51.4721744566,42.5158137034,28.9762559162,35.037329193,30.0053366319,28.9348344761,11.2189103247,26.597247305,24.5117793294,37.3351557851,38.4705254012,35.037329193,23.102144263,37.9257350271,30.6850392562,51.5329006301,39.8629242655,10.6131311978,35.037329193,38.9027374142,35.037329193,35.5607592951,56.4735842441,34.9529764947,23.9020256462,38.9540048881,28.036920539,33.1913905696,56.5464237178,23.7800556302,57.7102432656,54.4156878754,12.5516769526,35.037329193,6.9459020813,35.037329193,35.037329193,41.2973996316,35.037329193,19.8195621873,50.8476433472,35.037329193,49.0536404727,17.6294317116,7.9717248297,42.1074927565,38.10762796,52.7708487981,44.3691915844,48.4053748927,17.6400397817,11.468933083,45.2862703468,48.6032496168,59.439803378,25.3444429378,22.9490670618,46.8083646838,21.1074088749,55.9146822106,51.6463523587,26.3106476151,45.3013929997,45.518029571,7.0843082613,54.2506214941,30.8098899744,49.7609905004,19.8829264608,53.8358704813,23.9628990453,35.037329193,54.4175366087,35.037329193,19.8395046178,57.053656056,57.0858216693,34.8328353993,38.278395518,27.4582857967,18.2994355302,20.3912081768,40.6785889085,45.3900972368,47.7031635798,47.5874704249,35.037329193,30.1707979775,35.037329193,33.4222040571,27.050299581,53.3745467827,21.7039857406,7.9069539692,9.4365092411,45.9291272713,37.4748657357,6.9662378912,35.037329193,42.3571787561,35.037329193,49.4897434981,42.6682914022,35.037329193,35.037329193,59.2117351316,23.0819769496,22.8678866769,48.9551744682,56.8876660656,59.1740627655,45.4493129303,23.1993155463,35.037329193,46.8516680397,33.9458507344,26.0290985456,54.4749087206,7.5606514561,30.0648811532,35.037329193,28.6509778777,35.037329193,8.0102570598,7.9340485598,39.3034078248,45.0166478767,35.4187571407,57.76818036,23.1173641919,17.8570130906,52.2473485632,14.1921544726,57.830129827,35.037329193,58.2228507758,35.037329193,53.5774437082,32.1343654361,59.584922971,35.037329193,33.6774027797,58.1888496015,31.862772806,38.13451965,42.0491726501,27.8179228213,38.025926725,35.4745444035,54.168322619,35.037329193,17.5768281859,57.0742775605,53.5255632496,27.8837484144,37.5878232703,17.3654897959,12.0991484237,28.3582058915,21.8477814535,35.4357105992,35.037329193,58.4892936523,59.1864339243],"pages_viewed":[7,3,14,10,16,16,10,13,9,12,9,9,4,11,18,11,4,18,9,7,6,15,18,9,15,16,7,10,12,14,5,18,5,3,5,17,19,19,12,9,1,18,4,10,7,1,9,2,11,9,7,17,17,2,6,14,6,2,1,10,9,2,16,2,9,2,16,16,19,7,12,15,8,6,10,3,19,17,7,4,9,9,8,15,14,9,8,17,2,3,8,12,1,10,3,6,7,18,11,19,5,19,11,12,10,8,9,4,5,8,9,15,15,16,14,8,18,10,6,12,2,7,16,3,13,3,18,11,8,6,1,9,8,5,16,11,9,4,6,14,19,9,12,11,14,16,1,13,13,2,4,6,5,3,1,4,2,5,3,9,6,18,6,19,12,11,2,15,12,12,9,9,3,12,16,1,3,2,9,19,15,18,9,16,17,5,12,11,15,3,1,16,2,2,3,8,15,7,6,9,1,8,3,9,15,6,15,3,14,14,4,12,9,7,9,3,13,15,18,19,1,6,2,14,9,14,4,8,3,19,14,9,8,14,6,16,19,14,9,3,10,9,9,13,7,14,9,19,15,14,6,4,8,17,9,1,14,11,3,9,14,9,4,4,8,2,9,14,9,16,17,16,12,3,11,14,18,5,16,9,3,12,1,9,9,4,3,17,2,1,8,13,15,8,9,9,14,9,15,9,19,8,19,6,19,4,7,4,12,13,3,12,2,2,9,1,8,6,6,18,17,12,6,8,19,10,1,9,17,9,8,9,3,16,13,17,13,6,17,14,17,9,11,1,7,17,10,11,9,9,5,17,9,17,19,7,9,9,13,11,9,19,11,13,14,9,1,8,12,19,12,8,8,13,12,16,1,13,7,5,8,14,13,15,17,15,18,18,2,4,1,4,18,5,19,15,8,9,1,12,19,9,9,7,2,9,10,2,19,11,13,10,14,9,19,9,7,9,9,2,6,9,16,8,2,17,9,12,3,11,1,13,15,5,17,6,11,18,4,3,13,9,6,12,2,3,3,12,9,9,8,11,16,4,1,7,2,5,7,4,5,1,1,15,19,10,18,9,11,15,11,17,17,6,5,8,2,16,12,6,1,4,17,13,18,5,3,11,13,4,14,11,10,19,18,6,15,10,5,5],"basket_value":[50.5746474517,56.891022415,8.3482957768,43.4814890919,0,30.7728695226,19.4888999183,78.2377356438,30.6683921361,0,0,71.7559841802,26.1195180435,33.2101193065,30.5283883871,39.6003991571,83.2055054657,46.5782248288,75.18780637,20.9350510536,38.4892874126,78.6204144754,25.8318380472,80.3640938273,31.1484772701,40.3501245482,100.1048776205,36.925430685,54.3603740825,68.4930926757,56.7952594902,57.6516004667,0,10.9328237295,60.448679903,28.0259462897,73.2730165221,91.1618427185,0,91.2142348228,37.668266244,46.0715233345,22.6283764246,55.654031872,52.0044464953,82.3076847588,27.7582017011,99.8240720581,69.9414225893,52.7290693033,44.5764690831,40.802916586,42.7596867678,55.0520587081,43.7300011792,0,55.2337788451,0,59.6740070301,43.3079889356,70.901927277,79.6722263209,79.6604168103,59.5431516816,63.044936623,0,0,73.7150408199,2.9801253943,61.3504158682,91.0438942313,39.3112911619,32.763590716,37.4040961674,4.8537202151,53.7795186335,50.8989632029,55.9108049863,62.4792986365,26.0601979346,58.1959759707,63.2959597975,35.3482480755,62.6035399476,52.4211987916,0,0,41.2786776994,70.9119582204,0,11.307032547,58.0096095658,56.8820974349,17.5658866161,72.5160834631,70.9466250841,0,0,45.7397716091,0,69.2119155474,54.4691584798,17.1932856234,25.3258726145,85.631575315,96.0668713375,66.1618692816,0,36.8011126278,66.4909825493,52.2776160278,1.6978565776,0,0,72.1175759883,17.2516641612,30.8952065083,0,0,39.2978431022,119.9986796495,108.6569009272,22.8972075089,28.7519678179,63.9857102704,0,36.8522264786,33.8552299638,105.5349782584,0,41.4569906739,31.0554580194,76.8214879197,35.0986752821,48.4915107691,0,4.4738860395,20.1189461689,34.9408487791,42.1023550921,43.4172822223,0,0,90.4737904451,78.4395235957,45.9467219843,0,38.8373527564,0,50.6147903878,0,0,64.9823320758,41.5826996617,60.138011619,0,87.5286342268,56.7868646175,80.0724937602,82.5417842652,16.4133282173,0,63.5483204818,39.0338814873,42.8417969223,88.5969446651,40.6890086542,0,24.9859999509,0,44.6534155884,9.0725673435,0,31.2609007198,44.1043364172,78.4752111928,75.5703549939,49.8096073678,36.3749424152,60.1880556027,0,109.4324268179,69.6231678757,76.0097065918,0,88.4794592389,0,21.4232563154,48.8248288818,48.1233474203,17.6438878246,23.1518793938,20.8030467402,21.0885479643,38.357062787,8.3304459148,0,81.3540364515,74.6992835631,18.5036227732,78.7461475188,0,0,89.0093957641,0,61.4727968521,7.9724201567,51.8132836978,0,0,0,32.9903757257,16.0478984205,24.2555826231,6.74466722,75.7199229668,0,13.3393738529,75.2451403945,61.0886106302,74.1350316785,77.4824967259,108.1236469082,45.3188069992,6.2717696301,58.1311340229,29.9298613136,21.2748415005,52.9977551665,75.9725819903,24.9201547521,88.23164262,20.3115812299,42.6829033602,0,38.3630237395,0,77.8222247537,31.2960697893,72.3469534818,12.0756759492,17.1969025371,75.8730022867,60.2152427823,36.8424286795,60.6509479451,21.3788259337,0,53.8566177017,38.7865518443,24.9414288323,0,48.350565701,36.0253376324,18.9855658946,50.3743114801,36.1003290549,18.9602713869,51.3058943227,98.2491641617,0,94.9332962373,113.4299514419,21.3974329287,50.271326246,113.1119575345,46.3676011577,0,0,34.0501429904,66.6676605401,122.8784792885,44.1197949958,0.1212103325,7.8425242768,48.9263094219,85.3162039416,69.1206104863,0,89.2743316075,28.3931273744,50.5728415987,34.3885363939,0,19.8119193702,39.680717857,49.1685330126,38.8558550042,45.1681549096,62.1512163031,87.1608730719,0,72.8426530219,12.2005556469,39.1877004329,41.7714490786,0,60.2705353709,2.1701452016,100.8069940858,0,64.3460678571,48.1367201024,86.8651788522,70.6821481034,0,48.2284375322,103.6793925759,85.0066362707,65.2860888631,87.6791876129,37.425141745,0,59.6465153914,48.2872866256,44.0684797317,86.4893611805,0,57.9070722061,40.1884232374,76.4336941784,71.0562734392,76.2097903068,35.0820810009,89.1226538014,105.163052713,0,25.7213513827,0,38.7386913322,33.0686835794,0,68.973273991,58.6985732225,56.0686716916,0,47.7846221851,73.8972652259,0,49.6582877456,58.6396278478,0,19.6986218215,18.1127095264,67.5186498463,0,89.9656733228,56.7977597448,96.7616363853,17.3878287029,36.9092159385,0,26.1293071101,44.4845935783,0,38.161195634,0,42.2761944527,84.4133578132,48.9506074966,0,73.5887769018,90.4444354582,27.0516427737,26.3257511482,60.3684024916,0,64.1343124929,40.2824055036,89.8999051264,70.3853676224,82.9011929102,0,81.4463080629,93.3413748309,48.8385852986,27.819481419,28.346383963,0,130.5303722727,0,0,77.6424254202,27.382594119,80.5506615268,63.9603852058,49.2806809251,0,0,0,0,55.3595218577,97.1918109819,0,21.0264493958,62.804809243,51.157755882,0,29.0204537652,0,0,70.9095656703,59.6083223291,55.2648490388,68.8050097108,55.594638619,14.2940291571,0,74.5438185874,0,0,0,0,78.307006457,45.7633239304,90.20847711,49.9655963277,0,59.2425698228,49.0884353147,0,116.5503044903,20.8670545525,0,97.4509690436,32.4930958305,41.096802171,0,32.9104569753,27.0142258621,20.0954809251,51.9427928511,37.9403732697,71.91086571,0,22.1746341942,53.2556382822,37.4648502764,20.250186721,70.6829471155,46.3602416207,37.7734993949,24.3329829073,19.1618971678,109.6630407174,60.0235594889,17.2661288839,58.6359769497,81.8604853039,55.0255283759,91.220640264,3.7156057379,0,57.8155226556,58.2948843012,0,31.2927172639,0,8.2416127789,19.6687470617,67.873634048,19.4778493613,20.5063359625,0,88.0672892755,63.0389709641,0,20.5327976233,65.8555365318,88.4417764695,75.225162781,39.3295126923,0,76.1074698173,41.0930944604,52.0658604385,44.6773868537,9.3341150127,60.9275063667,56.7937709334,37.2263347126,64.1331739959,8.7800135773,41.9299167235,50.7838241881,0,0,72.0093544004,40.9030722787,48.9765529246,66.870321177,38.365996734,41.0660780137,14.698894564,49.5518966804,39.9545454919,64.9726938516,0,73.7362711704,34.7521894731],"device_type":["Mobile","Mobile","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Desktop","Tablet","Desktop","Tablet","Desktop","Mobile","Desktop","Desktop","Mobile","Mobile","Desktop","Mobile","Desktop","Mobile","Desktop","Desktop","Mobile","Mobile","Desktop","Tablet","Tablet","Mobile","Desktop","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Desktop","Desktop","Mobile","Mobile","Mobile","Mobile","Desktop","Mobile","Desktop","Tablet","Mobile","Tablet","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Desktop","Tablet","Desktop","Mobile","Desktop","Desktop","Tablet","Tablet","Tablet","Mobile","Desktop","Mobile","Tablet","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Tablet","Unknown","Mobile","Mobile","Tablet","Tablet","Desktop","Desktop","Mobile","Tablet","Desktop","Desktop","Mobile","Tablet","Desktop","Unknown","Desktop","Desktop","Desktop","Desktop","Desktop","Tablet","Mobile","Mobile","Mobile","Desktop","Desktop","Tablet","Desktop","Desktop","Tablet","Mobile","Tablet","Mobile","Desktop","Desktop","Desktop","Mobile","Mobile","Desktop","Tablet","Mobile","Tablet","Mobile","Desktop","Desktop","Desktop","Tablet","Unknown","Desktop","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Mobile","Mobile","Mobile","Tablet","Unknown","Desktop","Desktop","Mobile","Tablet","Mobile","Mobile","Desktop","Mobile","Desktop","Mobile","Desktop","Mobile","Mobile","Desktop","Mobile","Mobile","Mobile","Desktop","Desktop","Mobile","Unknown","Tablet","Desktop","Desktop","Mobile","Desktop","Mobile","Mobile","Tablet","Desktop","Mobile","Mobile","Desktop","Mobile","Mobile","Mobile","Mobile","Desktop","Mobile","Desktop","Mobile","Desktop","Tablet","Desktop","Tablet","Tablet","Mobile","Desktop","Tablet","Unknown","Mobile","Tablet","Desktop","Mobile","Mobile","Desktop","Desktop","Desktop","Desktop","Desktop","Desktop","Desktop","Desktop","Desktop","Mobile","Mobile","Tablet","Mobile","Mobile","Mobile","Tablet","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Mobile","Tablet","Mobile","Mobile","Desktop","Tablet","Desktop","Tablet","Tablet","Mobile","Desktop","Mobile","Desktop","Mobile","Mobile","Tablet","Mobile","Tablet","Mobile","Mobile","Tablet","Desktop","Desktop","Mobile","Desktop","Desktop","Desktop","Mobile","Tablet","Desktop","Tablet","Desktop","Desktop","Mobile","Mobile","Tablet","Mobile","Mobile","Mobile","Mobile","Tablet","Unknown","Mobile","Mobile","Desktop","Desktop","Tablet","Desktop","Mobile","Desktop","Tablet","Desktop","Desktop","Mobile","Desktop","Desktop","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Tablet","Desktop","Desktop","Mobile","Desktop","Mobile","Tablet","Mobile","Desktop","Mobile","Desktop","Desktop","Mobile","Mobile","Desktop","Tablet","Tablet","Mobile","Mobile","Tablet","Desktop","Desktop","Tablet","Tablet","Desktop","Mobile","Mobile","Desktop","Mobile","Mobile","Mobile","Mobile","Desktop","Desktop","Mobile","Mobile","Tablet","Mobile","Desktop","Tablet","Mobile","Desktop","Unknown","Mobile","Desktop","Mobile","Mobile","Tablet","Tablet","Desktop","Mobile","Mobile","Desktop","Unknown","Desktop","Desktop","Desktop","Desktop","Mobile","Mobile","Mobile","Desktop","Desktop","Desktop","Desktop","Tablet","Mobile","Mobile","Mobile","Desktop","Mobile","Tablet","Desktop","Unknown","Tablet","Unknown","Mobile","Desktop","Mobile","Mobile","Desktop","Mobile","Desktop","Desktop","Mobile","Mobile","Mobile","Desktop","Mobile","Tablet","Mobile","Mobile","Mobile","Mobile","Mobile","Desktop","Desktop","Mobile","Unknown","Desktop","Desktop","Mobile","Tablet","Mobile","Desktop","Unknown","Mobile","Tablet","Mobile","Desktop","Mobile","Desktop","Tablet","Mobile","Tablet","Desktop","Desktop","Desktop","Tablet","Mobile","Mobile","Tablet","Desktop","Mobile","Desktop","Desktop","Mobile","Mobile","Desktop","Mobile","Desktop","Tablet","Mobile","Unknown","Mobile","Mobile","Desktop","Mobile","Desktop","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Tablet","Desktop","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Mobile","Desktop","Mobile","Mobile","Desktop","Tablet","Tablet","Desktop","Unknown","Desktop","Unknown","Mobile","Desktop","Tablet","Mobile","Mobile","Mobile","Mobile","Mobile","Desktop","Desktop","Mobile","Tablet","Mobile","Mobile","Unknown","Desktop","Desktop","Tablet","Desktop","Tablet","Mobile","Desktop","Tablet","Desktop","Mobile","Desktop","Desktop","Mobile","Tablet","Mobile","Mobile","Tablet","Mobile","Mobile","Desktop","Desktop","Mobile","Tablet","Desktop","Unknown","Desktop","Desktop","Mobile","Mobile","Desktop","Tablet","Mobile","Desktop","Tablet","Mobile","Mobile","Mobile","Desktop","Unknown","Mobile","Desktop"],"customer_type":["Returning","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","Returning","New","New","Returning","Returning","Returning","Returning","Returning","Returning","Returning","Returning","Returning","Returning","Returning","New","New","New","New","New","New","New","Returning","Returning","New","Returning","Returning","Returning","Returning","New","New","Returning","New","Returning","New","New","New","New","Returning","Returning","New","New","New","New","Returning","New","Returning","New","New","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","New","New","New","Returning","New","Returning","Returning","New","Returning","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","New","New","Returning","New","New","Returning","Returning","New","Returning","Returning","Returning","New","New","Returning","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","New","Returning","Returning","Returning","Returning","Returning","New","Returning","New","Returning","New","Returning","New","New","Returning","Returning","New","New","Returning","Returning","New","Returning","New","Returning","New","Returning","New","Returning","New","New","New","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","New","Returning","New","Returning","New","Returning","Returning","New","New","Returning","Returning","New","New","New","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","New","Returning","New","New","New","Returning","New","Returning","New","Returning","Returning","Returning","Returning","New","New","Returning","New","New","Returning","Returning","Returning","Returning","Returning","Returning","Returning","New","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","Returning","New","New","New","Returning","Returning","Returning","New","New","Returning","Returning","New","Returning","Returning","New","New","Returning","Returning","New","New","New","Returning","Returning","Returning","Returning","New","Returning","Returning","New","New","Returning","New","New","Returning","Returning","New","New","New","Returning","Returning","New","New","New","Returning","Returning","New","Returning","Returning","New","New","Returning","New","New","New","Returning","New","New","New","Returning","New","New","Returning","New","New","New","New","New","New","Returning","New","New","Returning","Returning","New","New","Returning","Returning","Returning","New","Returning","New","New","Returning","New","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","New","New","New","Returning","Returning","Returning","New","Returning","Returning","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","Returning","New","New","Returning","New","New","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","New","New","Returning","Returning","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","Returning","Returning","New","Returning","Returning","Returning","New","Returning","Returning","Returning","New","New","Returning","New","New","New","Returning","Returning","New","New","Returning","Returning","New","New","Returning","Returning","Returning","Returning","New","Returning","Returning","Returning","New","New","Returning","New","Returning","New","New","New","New","New","New","Returning","Returning","New","Returning","Returning","Returning","Returning","New","Returning","Returning","New","Returning","Returning","Returning","Returning","Returning","Returning","New","New","New","Returning","New","Returning","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","Returning","New","Returning","Returning","Returning","New","Returning","Returning","New","Returning","New","New","New","New","Returning","New","Returning","Returning","Returning","Returning","Returning","Returning","New","Returning","Returning","New","New","New","Returning","Returning","Returning","New","Returning","New","New","Returning","New","New","New","Returning","Returning","Returning","Returning","New","Returning","Returning","New","New","New","Returning","New","Returning","New"],"purchase":[0,1,0,1,1,0,0,1,1,0,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,0,1,0,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1,0,1,0,1,1,1,0,1,1,1,1,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1]}},"total_rows":500,"truncation_type":null},"text/plain":"     customer_id  time_spent  pages_viewed  ...  device_type customer_type purchase\n0              1   23.097867             7  ...       Mobile     Returning        0\n1              2   57.092144             3  ...       Mobile     Returning        1\n2              3   44.187643            14  ...       Mobile     Returning        0\n3              4   36.320851            10  ...       Mobile           New        1\n4              5   10.205100            16  ...       Mobile     Returning        1\n..           ...         ...           ...  ...          ...           ...      ...\n495          496   21.847781             6  ...       Mobile           New        1\n496          497   35.435711            15  ...      Desktop     Returning        1\n497          498   35.037329            10  ...      Unknown           New        1\n498          499   58.489294             5  ...       Mobile     Returning        1\n499          500   59.186434             5  ...      Desktop           New        1\n\n[500 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>time_spent</th>\n      <th>pages_viewed</th>\n      <th>basket_value</th>\n      <th>device_type</th>\n      <th>customer_type</th>\n      <th>purchase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>23.097867</td>\n      <td>7</td>\n      <td>50.574647</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>57.092144</td>\n      <td>3</td>\n      <td>56.891022</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>44.187643</td>\n      <td>14</td>\n      <td>8.348296</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>36.320851</td>\n      <td>10</td>\n      <td>43.481489</td>\n      <td>Mobile</td>\n      <td>New</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>10.205100</td>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>496</td>\n      <td>21.847781</td>\n      <td>6</td>\n      <td>39.954545</td>\n      <td>Mobile</td>\n      <td>New</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>497</td>\n      <td>35.435711</td>\n      <td>15</td>\n      <td>64.972694</td>\n      <td>Desktop</td>\n      <td>Returning</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>498</td>\n      <td>35.037329</td>\n      <td>10</td>\n      <td>0.000000</td>\n      <td>Unknown</td>\n      <td>New</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>499</td>\n      <td>58.489294</td>\n      <td>5</td>\n      <td>73.736271</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>500</td>\n      <td>59.186434</td>\n      <td>5</td>\n      <td>34.752189</td>\n      <td>Desktop</td>\n      <td>New</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 7 columns</p>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":19}]},{"source":"# Task 2\nThe pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\nCreate the model features:\n\n- Start with the data in the file `model_data.csv`\n- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n","metadata":{},"id":"026b3c30-d3b0-4762-ae10-0f2880873bdc","cell_type":"markdown"},{"source":"# Write your answer to Task 2 here\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load data\ndf = pd.read_csv(\"model_data.csv\")\n\n# --- Scale numerical features ---\nnum_cols = [\"time_spent\", \"pages_viewed\", \"basket_value\"]\nscaler = MinMaxScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\n# --- One-hot encode categorical features ---\ncat_cols = [\"device_type\", \"customer_type\"]\ndf_encoded = pd.get_dummies(df, columns=cat_cols, prefix=cat_cols)\n\n# --- Final feature set ---\nmodel_feature_set = df_encoded.copy()\n\n# Output\nmodel_feature_set\n","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1755978505240,"lastExecutedByKernel":"4e5ba344-4ca8-4599-9705-ae72ac1e68a5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Write your answer to Task 2 here\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load data\ndf = pd.read_csv(\"model_data.csv\")\n\n# --- Scale numerical features ---\nnum_cols = [\"time_spent\", \"pages_viewed\", \"basket_value\"]\nscaler = MinMaxScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\n# --- One-hot encode categorical features ---\ncat_cols = [\"device_type\", \"customer_type\"]\ndf_encoded = pd.get_dummies(df, columns=cat_cols, prefix=cat_cols)\n\n# --- Final feature set ---\nmodel_feature_set = df_encoded.copy()\n\n# Output\nmodel_feature_set\n","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"202a8caf-26e5-42eb-8ac1-bc38f27a76c1","nodeType":"const"}}}}},"id":"6d47e440-c4ab-45cf-af40-53181764bac4","cell_type":"code","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"time_spent","type":"number"},{"name":"pages_viewed","type":"number"},{"name":"basket_value","type":"number"},{"name":"purchase","type":"integer"},{"name":"device_type_Desktop","type":"integer"},{"name":"device_type_Mobile","type":"integer"},{"name":"device_type_Tablet","type":"integer"},{"name":"device_type_Unknown","type":"integer"},{"name":"customer_type_New","type":"integer"},{"name":"customer_type_Returning","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],"customer_id":[501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],"time_spent":[0.6641673486,0.4836806636,0.2313587256,0.792944242,0.6492102097,0.0677492838,0.9011170419,0.8026801597,0.9444082825,0.6948575301,0.5697880236,0.3524314042,0.9253964096,0.8511543108,0.510473268,0.510473268,0.3059028024,0.7893340829,0.9861442742,0.0541625035,0.5483115512,0.3108335477,0.9668091022,0.8244876133,0.8202665755,0.4086159969,0.3486187305,0.1911324995,0.510473268,0.849660313,0.7919486128,1,0.9965689771,0.5052137756,0.7430435315,0.9388018831,0.8328718125,0.1621115076,0.3884040434,0.030488773,0.9491426041,0.5617244557,0.1412800532,0.6346985967,0.5750367816,0.28552199,0.0131135516,0.6345566167,0.466097362,0.7467531272,0.4659367716,0.8356939645,0.5012882509,0.5113459174,0.8629477155,0.3359935031,0.0358965277,0.510473268,0.7276190783,0.5774660336,0.6707580848,0.1238192787,0.0385206003,0.510473268,0.2770857919,0.5436196441,0.3234772089,0.3738493036,0.893579204,0.2744886204,0.4590609837,0.7593761105,0.3282645668,0.579445184,0.8470335449,0.9440972471,0.0504390609,0.9185575439,0.4347015466,0.1742463327,0.3979722405,0.9780773735,0.4352603853,0.2527678361,0.592045374,0.1540903464,0.510473268,0.0301772881,0.029248621,0.0558171913,0.0412554269,0.6003687925,0.0892019956,0.2716062479,0.8853711679,0.414483325,0.6300847383,0.0785551101,0.100794073,0.510473268,0.074785564,0.1969049284,0.0837788869,0.510473268,0.0209963909,0.399802007,0.116435179,0.2923233082,0.4472870625,0.6555176315,0.510473268,0.7769245774,0.5859196927,0.510473268,0.8595232161,0.912192692,0.510473268,0.1949975626,0.7844873513,0.7199597669,0.0921431153,0.119793556,0.2992305346,0.4262451369,0.5751776949,0.297494927,0.4017575469,0.7190813603,0.510473268,0.1677787792,0.6810815667,0.8836098245,0.4564861353,0.4792450639,0.0060021466,0.384916299,0.479806108,0.1566794919,0.1864953709,0.3068168953,0.510473268,0.2453369606,0.1221307888,0.2513710114,0.0200233371,0.8783983605,0.5477121073,0.6429415464,0.7655215716,0.4417464935,0.510473268,0.4848056618,0.5401933737,0.7168189877,0.3673729166,0.0287301691,0.2026799184,0.2910007577,0.60598445,0.5223047629,0.2832211646,0.9852969073,0.5612791952,0.1508397477,0,0.0568823525,0.1605630959,0.0655937094,0.0944216814,0.2041491368,0.0797286069,0.8853455699,0.510473268,0.4707788676,0.3436933468,0.9806900806,0.011422238,0.3297266063,0.9663146739,0.8505342621,0.7965937829,0.1738659475,0.0769600242,0.6312936021,0.9216628504,0.5066962739,0.5232339889,0.1984515374,0.7436065098,0.0949525933,0.2471189053,0.3604424526,0.4519567846,0.1566118131,0.0145381895,0.5666751559,0.2080863747,0.5339536176,0.0585568342,0.4224777344,0.4797751103,0.510473268,0.2615130862,0.03634138,0.510473268,0.9891334688,0.2456428617,0.7885780318,0.1702329768,0.645614794,0.7332883117,0.5499909878,0.4118267283,0.3453015778,0.2751710744,0.9218334141,0.8116809928,0.9613660734,0.025073915,0.7005906463,0.9316462742,0.0884814333,0.510473268,0.7120092588,0.5264195459,0.8241644871,0.0423080685,0.7723105617,0.1111938226,0.0689063868,0.0695855617,0.7938125681,0.6274559096,0.4691685456,0.2862656585,0.8635568219,0.3237011252,0.7960674293,0.3756979743,0.3064385455,0.4019191059,0.222282634,0.7192355385,0.44651097,0.1452557183,0.8884740236,0.3141749522,0.4919847091,0.8961555775,0.5818410091,0.0168336959,0.933307493,0.5857054942,0.2596213422,0.041750897,0.7709272519,0.5772023225,0.4807458478,0.8821461836,0.7648822967,0.0555634828,0.2338026118,0.163382243,0.7151560819,0.510473268,0.5213151371,0.7357727068,0.863072484,0.2676131595,0.8012547359,0.0098551258,0.8293135391,0.0286281122,0.3290937004,0.7745691367,0.0536062677,0.1419578189,0.6909965166,0.688528597,0.6006726987,0.659475173,0.4910621283,0.1670683878,0.2716382214,0.0888875323,0.8983589107,0.5363519793,0.333062947,0.401168515,0.9416056597,0.0574305701,0.5395126052,0.4500393859,0.5676041684,0.510473268,0.8579031491,0.9247168496,0.5160179828,0.6624847214,0.9140046052,0.674276007,0.0565258721,0.5284411249,0.5623262941,0.3589882638,0.7068012954,0.9272211865,0.9174225932,0.3887328379,0.0127576836,0.9834325747,0.8209006767,0.0254809128,0.9121587052,0.8554224056,0.4644606695,0.545131723,0.3310040981,0.510473268,0.2599461173,0.7807589851,0.510473268,0.2580550344,0.3300752891,0.4851275794,0.911060334,0.2723621054,0.2730383318,0.7079784544,0.390268104,0.1367830888,0.3905148648,0.0435159995,0.0830845186,0.4416636076,0.3531913847,0.9054811838,0.290234113,0.5332298782,0.5907796185,0.510473268,0.6256073924,0.0849209321,0.9569597497,0.0522089513,0.348401144,0.510473268,0.9968333779,0.4459258724,0.5497084248,0.510473268,0.721853868,0.1204130547,0.886780935,0.1151053748,0.0990107616,0.510473268,0.4123732673,0.5156927363,0.510473268,0.7503271323,0.3914607222,0.4706439801,0.3775108427,0.332964548,0.5099007794,0.0595341103,0.0892555029,0.8463897482,0.9403050341,0.3023902431,0.1881674762,0.6038487746,0.3418417033,0.510473268,0.0605501652,0.6840023153,0.6204695716,0.510473268,0.1338511835,0.1439884792,0.6349124865,0.510473268,0.0025905092,0.7774877433,0.0854874487,0.6135895272,0.1519044006,0.510473268,0.1574609374,0.6910125127,0.839608465,0.8112360351,0.3289781454,0.6306720836,0.1149323723,0.2131170016,0.8848671322,0.510473268,0.510473268,0.1181641865,0.510473268,0.0887068047,0.5359619358,0.3559745489,0.8807865399,0.7970074996,0.2673187095,0.1755593953,0.3094988762,0.544039781,0.1851817014,0.5817417948,0.3425961911,0.5014445451,0.3723476441,0.2145848462,0.9429086127,0.7370502026,0.042687605,0.8538316604,0.4294839153,0.8828808066,0.7774199996,0.3601941784,0.510473268,0.185865179,0.4898479776,0.5921315333,0.1738490848,0.0418444465,0.816481817,0.982943655,0.4720916491,0.0778417119,0.1899077503,0.510473268,0.9048719032,0.0177837,0.5286951693,0.1918543208,0.503817569,0.6121131183,0.8107036349,0.1165326842,0.510473268,0.0390931967,0.8889685677,0.8598700712,0.5519670341,0.5554235845,0.6272771148,0.0819533592,0.9049979026,0.3530188504,0.3133367034,0.464549371,0.510473268,0.071832462,0.7085713349,0.510473268,0.558358372,0.1598852979,0.3201936412,0.2081567401,0.2827489597,0.6874253644,0.2175426945,0.5174339611,0.4168095084,0.6257563935,0.9299638394,0.7024890261,0.1260201247,0.510473268,0.1787228873,0.5493664328,0.510473268,0.4394345764,0.5513319624,0.2588844028,0.7451871033,0.0053631715,0.510473268,0.6976074478,0.4384601955,0.6532987273,0.3709007796,0.1610579032,0.7988547999,0.7769306803,0.6603082247,0.1897271256,0.5439681994,0.2886527047,0.510473268,0.9082293491,0.039018582,0.9448954452,0.3833498231],"pages_viewed":[0.5,0.2222222222,0.1111111111,0.2777777778,0.1666666667,0.9444444444,0.4444444444,0.8888888889,0.6666666667,0.7777777778,0.5,0.6666666667,0.8333333333,0.1666666667,0.2222222222,0.2222222222,0.5,0.8888888889,0.6666666667,0.0555555556,0.6666666667,1,0.1111111111,0.5,0.0555555556,0.6666666667,1,0.8888888889,0.5,0.6111111111,0.6111111111,0.5555555556,0.3333333333,0.5,1,0,0.1111111111,0.6666666667,0.7777777778,0.0555555556,0.5555555556,0.1666666667,1,0.8888888889,0.1111111111,0.9444444444,0.5,1,0.2222222222,0.5,0.3888888889,0.2222222222,0.8888888889,0.2222222222,0.5,1,0.0555555556,0.5555555556,0.5,0.7777777778,0.6111111111,0.5555555556,0.5,0.5,0.8888888889,0.4444444444,0.7222222222,0.6111111111,0.2777777778,0.8888888889,1,1,0.8333333333,0.6111111111,0.6111111111,0.2777777778,0.1666666667,0.2777777778,0.5555555556,0,0.7777777778,0.5555555556,1,0.9444444444,0.8888888889,1,0.5,0.9444444444,1,0.7777777778,0.7777777778,0.1666666667,0.3333333333,0.6666666667,0.1111111111,0.8333333333,0.4444444444,0.3888888889,0.6666666667,0.8888888889,0.8888888889,0.5,0,0.3888888889,0.5,0.2777777778,0.5,0.2222222222,0.6666666667,0.5,0.7222222222,0.5,0.9444444444,0.5555555556,0.1111111111,0.5,0.5,0.8333333333,0.6111111111,0.0555555556,0.4444444444,0.1111111111,0.7777777778,0.1111111111,1,0.9444444444,0.3888888889,0.8888888889,0.3888888889,0.3333333333,0.3333333333,0.1111111111,0.5,0.1666666667,0.2222222222,0,0.7777777778,0.2222222222,0.6666666667,0.3888888889,0.3888888889,0.2222222222,0.4444444444,0,0.5,0.1111111111,0.0555555556,0.3888888889,0.4444444444,0.0555555556,0.7222222222,0.7222222222,0.1666666667,0.5,0.5555555556,0.1111111111,0.3888888889,0.1111111111,0.7222222222,0.6666666667,0.6666666667,0.0555555556,0.6666666667,1,0.2777777778,0.8333333333,0.0555555556,0.3888888889,0.8888888889,0.0555555556,0.5,0.8333333333,0.2777777778,0.0555555556,0.0555555556,0.6666666667,0.7777777778,0.5,0.3333333333,0.1111111111,0.3888888889,0.7222222222,0.5,0.3333333333,0,0.5,0.4444444444,0.6666666667,1,1,0.8888888889,0.5,0.5,0.1666666667,0.3888888889,0.9444444444,0.7222222222,0.9444444444,0.7222222222,0.7777777778,0.1666666667,0.6666666667,0.3888888889,0.5,0.6111111111,0.7222222222,0.0555555556,0.9444444444,0.5,0.5555555556,0.4444444444,0.6111111111,0.8888888889,0.7777777778,0.5,0.9444444444,0.2777777778,0.8888888889,0.9444444444,0.5,0.4444444444,0.2777777778,0.2222222222,0.6111111111,0.5555555556,0,0.5,1,0.4444444444,0.0555555556,0.6111111111,0.1666666667,0.5,0.9444444444,0.7777777778,1,0.6666666667,1,0.8888888889,0.5,0.8333333333,0.6111111111,1,0.2222222222,0.8888888889,0,0.5,0.7777777778,0.5555555556,0.6666666667,0.2222222222,0,0.6111111111,0.5555555556,0.8888888889,0.1666666667,0.7777777778,0.4444444444,1,0.5,0.6111111111,0.5,0.5,0.8888888889,0.2222222222,0.8333333333,0.3333333333,0.4444444444,0.1111111111,0.7777777778,0.5,0.9444444444,0.7222222222,0.1111111111,0.6111111111,0.4444444444,0.5,0.4444444444,0.6666666667,0.9444444444,0.5,0.6666666667,0.1666666667,0.0555555556,0.8333333333,0.4444444444,0.4444444444,0.2777777778,0.5555555556,0,0.1666666667,0.6666666667,0.6666666667,0.6666666667,0.0555555556,0.4444444444,0.5,0.3333333333,0.1666666667,0.9444444444,0.1111111111,0.2777777778,0.6111111111,0.6111111111,0.3888888889,0,0.1666666667,0.5555555556,0.1111111111,0.6666666667,0.8888888889,0.5,0.6111111111,0.7777777778,0.5,0.7222222222,0.6666666667,0.5,0.5,0.0555555556,0.8888888889,0.1666666667,0.7222222222,0.5,0.1111111111,0.1111111111,0.7777777778,0.2777777778,0.8888888889,0.5,0.5555555556,0.1666666667,0.2777777778,0,0.8333333333,0.7777777778,0.8888888889,0.5,0.6111111111,0.5,0.7777777778,0.4444444444,0.0555555556,0.2222222222,0.2777777778,0.3333333333,0,0.3333333333,0.6111111111,0.8333333333,0.8333333333,0.5555555556,0.1666666667,0.6666666667,0.3333333333,0.1666666667,0.7777777778,0.5,0.5,0.5555555556,0.3888888889,0,0.3888888889,0.6666666667,0.1666666667,0.3888888889,0.1111111111,0.4444444444,0.0555555556,0.0555555556,0.6666666667,0.7777777778,0.6111111111,0.1666666667,0.3888888889,0.4444444444,0.2222222222,0.9444444444,0.5555555556,0.7777777778,0.4444444444,0.8888888889,0.6111111111,0.5,0.5,0.5,0.6666666667,1,0.5555555556,0.6666666667,0.3888888889,0.3888888889,0.1666666667,0.7777777778,0.5555555556,0.5555555556,0,0.8888888889,0.7777777778,0.5,0.7777777778,0.4444444444,0.5,0.9444444444,0.8888888889,0.5,0.2222222222,0.4444444444,0.5555555556,0,0.9444444444,0.5,0.0555555556,0.7777777778,0.7222222222,0.2222222222,0.2777777778,0.2777777778,0.9444444444,0.7222222222,0.5,0.7222222222,0.6666666667,0.1111111111,0.2777777778,0.3888888889,0.6111111111,0.6666666667,0.5555555556,0.6111111111,0,0.8888888889,0.5,0.5555555556,0.6666666667,0.9444444444,0.5555555556,0.6111111111,0.2777777778,0.5,0.8333333333,0.1666666667,0.1111111111,0.8333333333,0.6111111111,0.5555555556,0.2222222222,0.9444444444,1,0.2777777778,0.9444444444,0.2777777778,0.1666666667,0.6111111111,1,0.0555555556,0.8888888889,0.5555555556,0.5555555556,0.8333333333,0.0555555556,0.0555555556,0.3888888889,0.6666666667,0.5,0.3888888889,0.1666666667,0.7777777778,0,0.5555555556,0.3333333333,0.8888888889,0.9444444444,0.6111111111,0.4444444444,0.5,0.5,0.5,0.2222222222,0.5,0.5555555556,0.5,0.3888888889,0.0555555556,0.3888888889,0.8333333333,0.5,0.1111111111,0.6111111111,0.6666666667,0.6666666667,0.5,0.1666666667,0.4444444444,0.0555555556,1,0,0.3333333333,0.8888888889,0.1111111111],"basket_value":[0,0.524980668,0.4572914583,0,0.4842825026,0.047538028,0.587891959,0,0.1826166328,0.2277893206,0.312851651,0.3606940002,0,0.2696634338,0.4069622037,0.3651172601,0.2221496705,0.1893169118,0.495928559,0,0.3757674924,0.5647755309,0,0.2402815111,0.1112498179,0.8551516077,0.5187854797,0.3460779585,0.5344306071,0.6066466109,0.6043263582,0.5642323103,0.306081976,0.2540210929,0.1535672785,0.4728396999,0.32866648,0.2720910326,0,0,0.570984893,0.7623154426,0.4786314168,0.3757278373,0.3577750654,0.1408995094,0,0.4739064773,0.1595642166,0.4094076267,0.6064702633,0,0.8015723253,0.14735334,0.5791625505,0.4559040153,0.6236103071,0.1199953672,0.8662141789,0.3243417502,0.5108132671,0.6781926826,0.231503716,0,0.195141751,0.6678326292,0.197602593,0.3717065223,0,0.5342800194,0.7924156897,0.2647888966,0.6115424161,0.792804174,0.399440281,0.243390425,0,0.7738430377,0.3100266761,0.1450288569,0.0672135174,0.1446243394,0.5637967294,0.593914586,0.5054668912,0.3921604725,0.0918045759,0,0.1220832951,0.4881802946,0.1315236644,0.2076157655,0.3233145585,0,0.3735080686,0.3399544944,0.6214552602,0.1845920503,0.080104113,0.2817721581,0.123942318,0.371847693,0,0.2313547573,0.1609390726,0.4870764215,0.186619516,0,0.3193182257,0.4330436584,0.3041931427,0,0.2169203458,0,0.1694237823,0.2917073037,0.5269004455,0.0796403314,0.3537936179,0,0.4129982983,0.1499443197,0,0.0413564463,0.4596801811,0.6295037795,0.1386350872,0.1754323503,0.1574896441,0.2574004944,0,0.2396035063,0.1189576129,0,0,0.7296395048,0.4854371474,0.1866589751,0.5263021885,0.5701187207,0.3078895701,0.3723303069,0.6318225454,0,0.5809561661,0.2959208188,0.1207843314,0.1387185607,0.174813875,0.0995322039,0,0.4703885771,0.5953564045,0.4859017337,0.3766593345,0.3796082071,0.2766596998,0.2944758745,0.056363563,0.5991370482,0,0.1325486173,0.8019107501,0.3929964667,0.4020511356,0.5022443116,0,0.0594829656,0.2663310803,0.166391095,0.3469730192,0.4691561536,0.6661326466,0,0.146572598,0.281575004,0,0.1417149283,0.092097873,0.7261117603,0.3656323577,0.3144331021,0.4688745729,0.4796624548,0.6072024769,0.201203554,0,0,0.3218604292,0.3756816516,0.3969880602,0.3873611027,0.5381016044,0.2331764815,0.4029152004,0.1978807214,1,0.1643194813,0,0.5557187199,0.2696944536,0,0.3966694928,0.275422266,0.1992212334,0.1913559805,0.2777914116,0.3252962663,0.1819727784,0.3395011787,0.1248090364,0.5280894901,0.5698256326,0.2097784021,0.1976042663,0.4020961199,0.6391464593,0.6873865612,0.0575321177,0.5826743449,0.3498946243,0,0.4733334632,0.2584697705,0.6023794989,0,0.6818541724,0,0.3132500705,0,0,0,0.461464975,0.4111192386,0.2690108528,0,0.4317674471,0.1428351241,0.1280032459,0.1012007931,0.3188777092,0,0,0.4770602589,0.57329909,0,0.3764215907,0,0.4044786251,0,0.2827231489,0.283725637,0.2519616766,0.3543882204,0.3154684671,0.1483055871,0,0.2240074904,0,0.0587689358,0.3826946925,0.6013311278,0,0.1735779951,0.4573640198,0.5547481059,0.2717329814,0,0.6291941657,0.5368507319,0,0.2612803852,0.6060838924,0,0.6099064891,0.3488093048,0,0.1572592283,0,0.3867906386,0,0.5164906304,0.4929667745,0.4435671253,0.1619385962,0.5306126639,0.1375597667,0.604638635,0.3450054851,0.3522585063,0,0.581620113,0,0.1844629353,0.5295649022,0.1856985406,0.5350651301,0.0526447352,0,0.1843684835,0,0,0.4066912322,0.3995221971,0.5168142847,0.6077014995,0,0.2543895124,0.504408696,0,0.5616051369,0.2085006119,0,0.5630002097,0.2727366057,0.5044395177,0.6115803415,0.3872983189,0.4312042833,0.3372769556,0.388511399,0.119950207,0.2992812539,0.0824997761,0.1673924713,0,0.4208455173,0.7320605905,0.2638871379,0.5736995299,0.6086994323,0.101915567,0.1488577159,0.5792940693,0.34318322,0,0.2244850596,0.4547931649,0,0,0.2931176379,0.3107789806,0.3653237291,0,0.3749797822,0.4162697858,0.5934063364,0,0.8290472745,0,0.1596799674,0.4971477337,0.6367371395,0.3195416847,0.1430097104,0.7471861799,0,0.4372221103,0.6497811355,0.267048068,0.2276963967,0.2426154812,0,0.5944114182,0.3706641953,0.773800854,0.3702807918,0,0.2691415368,0.8720422088,0.7055814867,0,0.6760243,0.6650029141,0.7018560066,0,0.5201220981,0.4815268289,0.4660005636,0.4109092726,0.4173322404,0.6430210152,0.480910928,0.4105953729,0,0.4544369589,0.4752639738,0.7703032133,0,0.032906591,0.3790868219,0,0.5205967833,0.3867060086,0.5279190298,0,0,0.5763549904,0,0.0613437671,0,0.2502466041,0,0.4752597443,0.2798631686,0.0770131924,0.3918414026,0.2022999046,0.4615760655,0.5175661687,0.2103214149,0.311588153,0.4101570676,0.0565948826,0.4101378344,0.0513683199,0.4866317058,0.2684522477,0.0501641383,0.2368854932,0.2461061499,0.5962366663,0.4010907381,0.15485596,0,0.4998795514,0.2899984132,0.0245960692,0.2707563936,0.3152433882,0.4437569132,0.4956868036,0.5391372876,0.0120327428,0.4087639243,0.3285182289,0.9470780242,0.3774150602,0.2275818745,0.3873715118,0.3614447023,0,0.4523177466,0.2956147034,0.3574941309,0.1728854706,0.1248528655,0.5548978351,0.6049421652,0.4544527471,0,0,0,0.2191844654,0.5519933948,0.5066607237,0.4629256503,0.6495088348,0.4853887777,0,0.2827593805,0.3542423586,0.3287087714,0.2287847346,0.1387513329,0.8866448497,0.2785709735,0.8759323089,0.1145254522,0.5065433564,0.4133714376,0.1623390194,0.2613908815,0.360014316,0.17930562,0.3074770369,0,0.518414066,0,0,0.8568924259,0.5120009258,0.6124306855,0.6332600863,0,0.4556679386,0.0618499644,0.1058903036,0.1438049067,0.2951443498,0.5051046155,0.4579168341,0.3605698978,0.5208484306,0,0.4597990175,0,0.2021471835,0.3690516203,0.5231960342],"purchase":[1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,0,1,1,1,0,1,1,1,1,1,0,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,0,0,1,1,0,0,1,1,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,1,1,1,1,1,0,1,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1],"device_type_Desktop":[1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,0,1,0,1,0,1,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,1,1,1,1,0,0,0,1,0,0,0,0,1,0,0,1,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,1,0,1,1,1,0,0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,0,1,1,0,0,1,0,1,1,0,0,0,0,1,0,1,0,1,1,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,1,0,0,1,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1,0,1,0,0,0,1,0,1,0,1,1,0,1,0,0,0,1,0,1,1,1,0,0,0,0,1,1,1,0,1,0,1,1,0,1,0,0,1,0,0,0,1,1,0,1,0,1,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,1,0,1,0,1,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0],"device_type_Mobile":[0,1,1,0,0,0,0,1,1,1,1,0,1,1,0,1,1,1,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1,0,0,1,1,0,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,0,1,0,1,0,0,1,0,0,1,0,1,0,0,1,0,0,0,0,0,1,1,0,1,0,1,1,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,0,0,1,1,1,1,0,1,0,1,0,0,1,1,1,0,1,0,0,0,1,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,1,1,1,0,1,0,1,0,0,1,0,1,0,1,1,0,0,1,0,1,1,0,1,1,0,1,0,1,1,1,0,0,1,1,0,1,0,0,0,1,0,0,1,1,0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,0,0,1,1,0,1,0,1,0,0,0,1,1,1,1,1,1,0,0,1,1,0,1,0,1,1,0,1,0,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1,0,1,1,0,0,0,1,0,1,0,1,0,1,1,0,0,1,0,1,0,0,1,0,1,1,0,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,0,0,1,1,1,1,0,0,0,1,0,1,1,1,0,1,0,0,0,1,0,0,1,1,1,1,0,0,1,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,1,0,0,0,1,0,0,0,1,1,0,1,1,1,0,0,0,1,1,0,0,0,0,1,0,1,1,0,1,1,1,1,0,1,0,1,1,1,0,1,0,0,0,1,1],"device_type_Tablet":[0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,0,1,1,1,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],"device_type_Unknown":[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],"customer_type_New":[1,0,0,1,1,1,1,1,0,0,0,1,1,1,0,0,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,0,1,0,1,0,1,0,0,1,0,1,0,0,0,1,0,1,0,0,1,1,0,0,1,1,0,1,1,1,1,0,0,0,1,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1,1,0,1,0,0,1,0,0,0,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,0,0,0,1,0,0,0,0,0,1,0,0,1,1,0,0,1,1,1,0,1,0,1,0,0,1,1,0,1,1,0,0,0,1,1,1,0,0,0,1,0,1,1,0,1,0,1,0,0,0,0,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,0,1,1,1,1,1,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1,1,0,0,1,1,0,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,1,1,0,0,0,1,0,1,1,1,0,0,0,0,1,0,0,1,0,1,0,1,1,0,0,0,1,0,0,0,1,1,0,0,1,1,0,0,1,0,0,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,0,1,0,0,0,0,1,0,1,1,1,1,1,0,0,0,1,1,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,1,0,1,0,0,1,1,0,0,1,0,0,1,0,1,0,0,0,1,1,0,0,0,0,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,1,1,1,0,0,0,0,0,1,0,0,1,0,1,1,0,0,1,1,0,0,1,0,1,1,0,0,1,1,0,0,0,1,0,0,0,0],"customer_type_Returning":[0,1,1,0,0,0,0,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,0,1,1,0,0,1,1,0,0,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,0,0,0,1,0,1,1,0,1,1,1,1,1,0,0,0,1,0,0,0,0,1,0,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,1,0,0,1,0,0,0,1,1,1,0,1,1,1,1,1,0,1,1,0,0,1,1,0,0,0,1,0,1,0,1,1,0,0,1,0,0,1,1,1,0,0,0,1,1,1,0,1,0,0,1,0,1,0,1,1,1,1,0,1,1,1,1,0,0,0,0,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,0,0,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,1,1,1,1,0,0,1,1,0,0,1,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,1,1,0,0,1,1,1,0,1,0,0,0,1,1,1,1,0,1,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,1,0,1,1,1,1,0,1,0,0,0,0,0,1,1,1,0,0,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,1,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,0,1,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,0,1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,1,1,0,1,1,1,1]}},"total_rows":500,"truncation_type":null},"text/plain":"     customer_id  time_spent  ...  customer_type_New  customer_type_Returning\n0            501    0.664167  ...                  1                        0\n1            502    0.483681  ...                  0                        1\n2            503    0.231359  ...                  0                        1\n3            504    0.792944  ...                  1                        0\n4            505    0.649210  ...                  1                        0\n..           ...         ...  ...                ...                      ...\n495          996    0.510473  ...                  1                        0\n496          997    0.908229  ...                  0                        1\n497          998    0.039019  ...                  0                        1\n498          999    0.944895  ...                  0                        1\n499         1000    0.383350  ...                  0                        1\n\n[500 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>time_spent</th>\n      <th>pages_viewed</th>\n      <th>basket_value</th>\n      <th>purchase</th>\n      <th>device_type_Desktop</th>\n      <th>device_type_Mobile</th>\n      <th>device_type_Tablet</th>\n      <th>device_type_Unknown</th>\n      <th>customer_type_New</th>\n      <th>customer_type_Returning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>501</td>\n      <td>0.664167</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>502</td>\n      <td>0.483681</td>\n      <td>0.222222</td>\n      <td>0.524981</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>503</td>\n      <td>0.231359</td>\n      <td>0.111111</td>\n      <td>0.457291</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504</td>\n      <td>0.792944</td>\n      <td>0.277778</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>505</td>\n      <td>0.649210</td>\n      <td>0.166667</td>\n      <td>0.484283</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>996</td>\n      <td>0.510473</td>\n      <td>1.000000</td>\n      <td>0.459799</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>997</td>\n      <td>0.908229</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>998</td>\n      <td>0.039019</td>\n      <td>0.333333</td>\n      <td>0.202147</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>999</td>\n      <td>0.944895</td>\n      <td>0.888889</td>\n      <td>0.369052</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>1000</td>\n      <td>0.383350</td>\n      <td>0.111111</td>\n      <td>0.523196</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 11 columns</p>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":20}]},{"source":"# Task 3\n\nNow that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n\n- Using PyTorch, create a network with:\n   - At least one hidden layer with 8 units\n   - ReLU activation for hidden layer\n   - Sigmoid activation for the output layer\n- Using the prepared features in `input_model_features.csv`, train the model to predict purchases. \n- Use the validation dataset `validation_features.csv` to predict new values based on the trained model. \n- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n","metadata":{},"id":"10a02327-d528-441c-87bf-098f9d6415e1","cell_type":"markdown"},{"source":"# Task 3A — Create network model (PyTorch)\n# Builds a model with one hidden layer of EXACTLY 8 units, ReLU hidden, Sigmoid output\nimport pandas as pd\nimport torch\nfrom torch import nn\n\n# Determine input dimension from training features file\ntrain_df = pd.read_csv(\"input_model_features.csv\")\nfeature_cols = [c for c in train_df.columns if c not in [\"customer_id\", \"purchase\"]]\ninput_dim = len(feature_cols)\n\n# Define the model with required activations and sizes\npurchase_model = nn.Sequential(\n    nn.Linear(input_dim, 8),  # exactly 8 hidden units\n    nn.ReLU(),\n    nn.Linear(8, 1),\n    nn.Sigmoid()\n)\n\n# Display the model (optional)\npurchase_model\n\n# Task 3B — Train purchase_model on input_model_features.csv and predict on validation_features.csv\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# -----------------------------\n# 1) Load prepared feature data\n# -----------------------------\ntrain_df = pd.read_csv(\"input_model_features.csv\")\nval_df   = pd.read_csv(\"validation_features.csv\")\n\nTARGET = \"purchase\"\nIDCOL  = \"customer_id\"\n\n# Training feature columns (exclude ID and target)\nfeature_cols = [c for c in train_df.columns if c not in [IDCOL, TARGET]]\n\n# Align validation columns with training feature space\nmissing_in_val = [c for c in feature_cols if c not in val_df.columns]\nextra_in_val   = [c for c in val_df.columns if c not in feature_cols + [IDCOL]]\n\n# Add missing validation columns (unseen categories, etc.) as zeros\nfor c in missing_in_val:\n    val_df[c] = 0\n\n# Drop any extra columns in validation not present in training features\nif extra_in_val:\n    val_df = val_df.drop(columns=extra_in_val)\n\n# Reorder validation columns to match training order\nval_df = val_df[[IDCOL] + feature_cols]\n\n# Numpy tensors\nX_train = train_df[feature_cols].fillna(0).astype(np.float32).values\ny_train = train_df[TARGET].astype(np.float32).values.reshape(-1, 1)\nX_val   = val_df[feature_cols].fillna(0).astype(np.float32).values\nval_ids = val_df[IDCOL].values\n\n# -----------------------------\n# 2) Dataset & DataLoader\n# -----------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n\ninput_dim = X_train.shape[1]\n\n# -----------------------------\n# 3) Model (reuse if exists; else rebuild identically to 3A)\n# -----------------------------\nif 'purchase_model' not in globals():\n    purchase_model = nn.Sequential(\n        nn.Linear(input_dim, 8),\n        nn.ReLU(),\n        nn.Linear(8, 1),\n        nn.Sigmoid()\n    )\n\n# Loss & optimizer\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(purchase_model.parameters(), lr=1e-3)\n\n# -----------------------------\n# 4) Train\n# -----------------------------\npurchase_model.train()\nEPOCHS = 200\nfor epoch in range(EPOCHS):\n    for xb, yb in train_loader:\n        optimizer.zero_grad()\n        preds = purchase_model(xb)\n        loss = criterion(preds, yb)\n        loss.backward()\n        optimizer.step()\n\n# -----------------------------\n# 5) Predict on validation set\n# -----------------------------\npurchase_model.eval()\nwith torch.no_grad():\n    val_probs = purchase_model(torch.from_numpy(X_val)).numpy().ravel()\n    val_pred_labels = (val_probs >= 0.5).astype(int)\n\n# -----------------------------\n# 6) Output DataFrame\n# -----------------------------\nvalidation_predictions = pd.DataFrame({\n    \"customer_id\": val_ids,\n    \"purchase\": val_pred_labels\n})\n\n# Final output for grading\nvalidation_predictions\n","metadata":{"executionCancelledAt":null,"executionTime":6288,"lastExecutedAt":1755978511528,"lastExecutedByKernel":"4e5ba344-4ca8-4599-9705-ae72ac1e68a5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 3A — Create network model (PyTorch)\n# Builds a model with one hidden layer of EXACTLY 8 units, ReLU hidden, Sigmoid output\nimport pandas as pd\nimport torch\nfrom torch import nn\n\n# Determine input dimension from training features file\ntrain_df = pd.read_csv(\"input_model_features.csv\")\nfeature_cols = [c for c in train_df.columns if c not in [\"customer_id\", \"purchase\"]]\ninput_dim = len(feature_cols)\n\n# Define the model with required activations and sizes\npurchase_model = nn.Sequential(\n    nn.Linear(input_dim, 8),  # exactly 8 hidden units\n    nn.ReLU(),\n    nn.Linear(8, 1),\n    nn.Sigmoid()\n)\n\n# Display the model (optional)\npurchase_model\n\n# Task 3B — Train purchase_model on input_model_features.csv and predict on validation_features.csv\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# -----------------------------\n# 1) Load prepared feature data\n# -----------------------------\ntrain_df = pd.read_csv(\"input_model_features.csv\")\nval_df   = pd.read_csv(\"validation_features.csv\")\n\nTARGET = \"purchase\"\nIDCOL  = \"customer_id\"\n\n# Training feature columns (exclude ID and target)\nfeature_cols = [c for c in train_df.columns if c not in [IDCOL, TARGET]]\n\n# Align validation columns with training feature space\nmissing_in_val = [c for c in feature_cols if c not in val_df.columns]\nextra_in_val   = [c for c in val_df.columns if c not in feature_cols + [IDCOL]]\n\n# Add missing validation columns (unseen categories, etc.) as zeros\nfor c in missing_in_val:\n    val_df[c] = 0\n\n# Drop any extra columns in validation not present in training features\nif extra_in_val:\n    val_df = val_df.drop(columns=extra_in_val)\n\n# Reorder validation columns to match training order\nval_df = val_df[[IDCOL] + feature_cols]\n\n# Numpy tensors\nX_train = train_df[feature_cols].fillna(0).astype(np.float32).values\ny_train = train_df[TARGET].astype(np.float32).values.reshape(-1, 1)\nX_val   = val_df[feature_cols].fillna(0).astype(np.float32).values\nval_ids = val_df[IDCOL].values\n\n# -----------------------------\n# 2) Dataset & DataLoader\n# -----------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n\ninput_dim = X_train.shape[1]\n\n# -----------------------------\n# 3) Model (reuse if exists; else rebuild identically to 3A)\n# -----------------------------\nif 'purchase_model' not in globals():\n    purchase_model = nn.Sequential(\n        nn.Linear(input_dim, 8),\n        nn.ReLU(),\n        nn.Linear(8, 1),\n        nn.Sigmoid()\n    )\n\n# Loss & optimizer\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(purchase_model.parameters(), lr=1e-3)\n\n# -----------------------------\n# 4) Train\n# -----------------------------\npurchase_model.train()\nEPOCHS = 200\nfor epoch in range(EPOCHS):\n    for xb, yb in train_loader:\n        optimizer.zero_grad()\n        preds = purchase_model(xb)\n        loss = criterion(preds, yb)\n        loss.backward()\n        optimizer.step()\n\n# -----------------------------\n# 5) Predict on validation set\n# -----------------------------\npurchase_model.eval()\nwith torch.no_grad():\n    val_probs = purchase_model(torch.from_numpy(X_val)).numpy().ravel()\n    val_pred_labels = (val_probs >= 0.5).astype(int)\n\n# -----------------------------\n# 6) Output DataFrame\n# -----------------------------\nvalidation_predictions = pd.DataFrame({\n    \"customer_id\": val_ids,\n    \"purchase\": val_pred_labels\n})\n\n# Final output for grading\nvalidation_predictions\n","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"202a8caf-26e5-42eb-8ac1-bc38f27a76c1","nodeType":"const"}}}}},"id":"efcbda28-3c89-480d-b77a-c7f27ac759d5","cell_type":"code","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"purchase","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199],"customer_id":[1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000],"purchase":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},"total_rows":200,"truncation_type":null},"text/plain":"     customer_id  purchase\n0           1801         1\n1           1802         1\n2           1803         1\n3           1804         1\n4           1805         1\n..           ...       ...\n195         1996         1\n196         1997         1\n197         1998         1\n198         1999         1\n199         2000         1\n\n[200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>purchase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1801</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1802</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1803</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1804</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1805</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>1997</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>1998</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>1999</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>2000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 2 columns</p>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":21}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}